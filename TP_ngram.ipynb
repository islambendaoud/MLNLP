{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "da76bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:\n",
      "3.8.8 (default, Apr 13 2021, 12:59:45) \n",
      "[Clang 10.0.0 ]\n",
      "\n",
      "Python Executable Path:\n",
      "/Users/islambendaoud/opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python Version:\")\n",
    "print(sys.version)\n",
    "\n",
    "print(\"\\nPython Executable Path:\")\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e66defde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download fr_core_news_sm\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "772f4c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Tao_Te_King.txt\") as f:\n",
    "    txt_raw = f.read()\n",
    "txt = re.sub(\"\\n{2,}\",\"\\n\",txt_raw)\n",
    "\n",
    "phrases = txt.split(\"\\n\")\n",
    "sphrases = [nlp(p) for p in phrases]\n",
    "type(sphrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "70f79387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans le monde, lorsque tous les hommes ont su apprécier la beauté (morale), alors la laideur (du vice) a paru. 27\n",
      "1 Dans ADP\n",
      "2 le DET\n",
      "3 monde NOUN\n",
      "4 , PUNCT\n",
      "5 lorsque SCONJ\n",
      "6 tous ADJ\n",
      "7 les DET\n",
      "8 hommes NOUN\n",
      "9 ont AUX\n",
      "10 su VERB\n",
      "11 apprécier VERB\n",
      "12 la DET\n",
      "13 beauté NOUN\n",
      "14 ( PUNCT\n",
      "15 morale ADJ\n",
      "16 ) PUNCT\n",
      "17 , PUNCT\n",
      "18 alors ADV\n",
      "19 la DET\n",
      "20 laideur NOUN\n",
      "21 ( PUNCT\n",
      "22 du ADP\n",
      "23 vice NOUN\n",
      "24 ) PUNCT\n",
      "25 a AUX\n",
      "26 paru VERB\n",
      "27 . PUNCT\n"
     ]
    }
   ],
   "source": [
    "sphrase = sphrases[11]\n",
    "print(sphrase , len(sphrase))\n",
    "i = 1\n",
    "for token in sphrase :\n",
    "    print(i , token.text , token.pos_)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7376d56",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "1. Quel est le vocabulaire de ce corpus ? Taille ? Combien de mots de plus de 5 occurrences ? Quels sont les mots les plus fréquents ? Les moins fréquents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "b96cd36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11690\n"
     ]
    }
   ],
   "source": [
    "vocab = dict()\n",
    "cpt  = 0\n",
    "for phrase in sphrases : \n",
    "    for token in phrase : \n",
    "        if token.text in vocab : \n",
    "            vocab[token.text] += 1\n",
    "        else :\n",
    "            vocab[token.text] = 1 \n",
    "        cpt += 1 \n",
    "    \n",
    "print(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "cf1b510e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAO': 1,\n",
       " 'TSEU': 1,\n",
       " 'TAO': 1,\n",
       " 'TE': 1,\n",
       " 'KING': 1,\n",
       " 'LE': 1,\n",
       " 'LIVRE': 3,\n",
       " 'DE': 2,\n",
       " 'LA': 2,\n",
       " 'VOIE': 1,\n",
       " 'ET': 1,\n",
       " 'VERTU': 1,\n",
       " 'I.': 2,\n",
       " 'CHAPITRE': 81,\n",
       " 'La': 12,\n",
       " 'voie': 6,\n",
       " 'qui': 177,\n",
       " 'peut': 33,\n",
       " 'être': 56,\n",
       " 'exprimée': 1,\n",
       " 'par': 27,\n",
       " 'la': 224,\n",
       " 'parole': 3,\n",
       " 'n’': 96,\n",
       " 'est': 325,\n",
       " 'pas': 129,\n",
       " 'Voie': 5,\n",
       " 'éternelle': 5,\n",
       " ';': 133,\n",
       " 'le': 307,\n",
       " 'nom': 12,\n",
       " 'nommé': 2,\n",
       " 'Nom': 1,\n",
       " 'éternel': 4,\n",
       " '.': 717,\n",
       " '(': 110,\n",
       " 'L’': 22,\n",
       " ')': 110,\n",
       " 'sans': 19,\n",
       " 'l’': 228,\n",
       " 'origine': 12,\n",
       " 'du': 86,\n",
       " 'ciel': 31,\n",
       " 'et': 242,\n",
       " 'de': 309,\n",
       " 'terre': 16,\n",
       " 'avec': 18,\n",
       " 'un': 88,\n",
       " ',': 411,\n",
       " 'il': 226,\n",
       " 'mère': 8,\n",
       " 'toutes': 8,\n",
       " 'choses': 30,\n",
       " 'C’': 68,\n",
       " 'pourquoi': 68,\n",
       " 'lorsqu’': 10,\n",
       " 'on': 108,\n",
       " 'constamment': 12,\n",
       " 'exempt': 4,\n",
       " 'passions': 5,\n",
       " 'voit': 6,\n",
       " 'son': 34,\n",
       " 'essence': 3,\n",
       " 'spirituelle': 5,\n",
       " 'a': 71,\n",
       " 'des': 68,\n",
       " 'sous': 1,\n",
       " 'une': 83,\n",
       " 'forme': 6,\n",
       " 'bornée': 1,\n",
       " 'Ces': 2,\n",
       " 'deux': 10,\n",
       " 'ont': 28,\n",
       " 'même': 5,\n",
       " 'reçoivent': 1,\n",
       " 'noms': 1,\n",
       " 'différents': 1,\n",
       " 'On': 7,\n",
       " 'les': 233,\n",
       " 'appelle': 38,\n",
       " 'profondes': 4,\n",
       " 'Elles': 1,\n",
       " 'sont': 32,\n",
       " 'doublement': 3,\n",
       " 'porte': 2,\n",
       " 'spirituelles': 1,\n",
       " 'II': 2,\n",
       " 'Dans': 11,\n",
       " 'monde': 25,\n",
       " 'lorsque': 5,\n",
       " 'tous': 26,\n",
       " 'hommes': 57,\n",
       " 'su': 2,\n",
       " 'apprécier': 2,\n",
       " 'beauté': 1,\n",
       " 'morale': 2,\n",
       " 'alors': 6,\n",
       " 'laideur': 1,\n",
       " 'vice': 1,\n",
       " 'paru': 3,\n",
       " 'Lorsque': 10,\n",
       " 'bien': 10,\n",
       " 'mal': 5,\n",
       " 'non-être': 6,\n",
       " 'naissent': 5,\n",
       " 'autre': 7,\n",
       " 'Le': 45,\n",
       " 'difficile': 8,\n",
       " 'facile': 1,\n",
       " 'se': 96,\n",
       " 'produisent': 1,\n",
       " 'mutuellement': 4,\n",
       " 'long': 1,\n",
       " 'court': 1,\n",
       " 'donnent': 2,\n",
       " 'leur': 32,\n",
       " 'haut': 1,\n",
       " 'bas': 3,\n",
       " 'montrent': 3,\n",
       " 'inégalité': 1,\n",
       " 'Les': 42,\n",
       " 'tons': 1,\n",
       " 'voix': 3,\n",
       " 's’': 105,\n",
       " 'accordent': 1,\n",
       " 'antériorité': 1,\n",
       " 'postériorité': 1,\n",
       " 'conséquence': 1,\n",
       " 'De': 20,\n",
       " 'là': 25,\n",
       " 'vient': 23,\n",
       " 'que': 77,\n",
       " 'saint': 11,\n",
       " 'homme': 59,\n",
       " 'fait': 21,\n",
       " 'occupation': 2,\n",
       " 'non-agir': 13,\n",
       " 'Il': 86,\n",
       " 'consister': 3,\n",
       " 'ses': 38,\n",
       " 'instructions': 2,\n",
       " 'dans': 43,\n",
       " 'silence': 2,\n",
       " 'Alors': 3,\n",
       " 'êtres': 34,\n",
       " 'mettent': 1,\n",
       " 'en': 59,\n",
       " 'mouvement': 7,\n",
       " 'ne': 181,\n",
       " 'refuse': 1,\n",
       " 'rien': 11,\n",
       " 'produit': 14,\n",
       " 'approprie': 2,\n",
       " 'perfectionne': 2,\n",
       " 'compte': 2,\n",
       " 'sur': 19,\n",
       " 'eux': 14,\n",
       " 'Ses': 3,\n",
       " 'mérites': 4,\n",
       " 'étant': 1,\n",
       " 'accomplis': 2,\n",
       " 'y': 33,\n",
       " 'attache': 8,\n",
       " 'à': 157,\n",
       " 'c’': 42,\n",
       " 'ils': 46,\n",
       " 'quittent': 1,\n",
       " 'point': 74,\n",
       " 'III': 1,\n",
       " 'En': 6,\n",
       " 'exaltant': 1,\n",
       " 'sages': 1,\n",
       " 'empêche': 4,\n",
       " 'peuple': 40,\n",
       " 'disputer': 2,\n",
       " 'prisant': 1,\n",
       " 'biens': 3,\n",
       " 'd’': 83,\n",
       " 'acquisition': 3,\n",
       " 'livrer': 3,\n",
       " 'au': 48,\n",
       " 'vol': 2,\n",
       " 'regardant': 1,\n",
       " 'objets': 4,\n",
       " 'propres': 1,\n",
       " 'exciter': 1,\n",
       " 'désirs': 11,\n",
       " 'cœur': 7,\n",
       " 'trouble': 4,\n",
       " 'gouverne': 4,\n",
       " 'vide': 9,\n",
       " 'remplit': 1,\n",
       " 'ventre': 1,\n",
       " 'intérieur': 2,\n",
       " 'affaiblit': 1,\n",
       " 'sa': 45,\n",
       " 'volonté': 2,\n",
       " 'fortifie': 1,\n",
       " 'os': 2,\n",
       " 'étudie': 1,\n",
       " 'rendre': 2,\n",
       " 'ignorant': 3,\n",
       " 'sorte': 2,\n",
       " 'ceux': 8,\n",
       " 'savoir': 6,\n",
       " 'osent': 1,\n",
       " 'agir': 7,\n",
       " 'pratique': 6,\n",
       " 'soit': 4,\n",
       " 'gouverné': 1,\n",
       " 'IV': 1,\n",
       " 'Tao': 77,\n",
       " 'si': 8,\n",
       " 'usage': 8,\n",
       " 'paraît': 9,\n",
       " 'inépuisable': 1,\n",
       " 'Ô': 4,\n",
       " 'qu’': 67,\n",
       " 'profond': 3,\n",
       " '!': 20,\n",
       " 'semble': 8,\n",
       " 'patriarche': 1,\n",
       " 'émousse': 2,\n",
       " 'subtilité': 1,\n",
       " 'dégage': 4,\n",
       " 'liens': 2,\n",
       " 'tempère': 2,\n",
       " 'splendeur': 2,\n",
       " 'assimile': 2,\n",
       " 'poussière': 1,\n",
       " 'pur': 3,\n",
       " 'subsister': 4,\n",
       " 'éternellement': 2,\n",
       " 'J’': 5,\n",
       " 'ignore': 1,\n",
       " 'fils': 2,\n",
       " 'avoir': 12,\n",
       " 'précédé': 1,\n",
       " 'maître': 11,\n",
       " 'V.': 1,\n",
       " 'affection': 8,\n",
       " 'particulière': 2,\n",
       " 'Ils': 11,\n",
       " 'regardent': 4,\n",
       " 'créatures': 2,\n",
       " 'comme': 52,\n",
       " 'chien': 2,\n",
       " 'paille': 2,\n",
       " 'sacrifice': 2,\n",
       " 'regarde': 6,\n",
       " 'tout': 13,\n",
       " 'entre': 2,\n",
       " 'ressemble': 10,\n",
       " 'soufflet': 1,\n",
       " 'forge': 1,\n",
       " 'épuise': 1,\n",
       " 'met': 8,\n",
       " 'plus': 41,\n",
       " 'vent': 2,\n",
       " 'Celui': 68,\n",
       " 'parle': 6,\n",
       " 'beaucoup': 3,\n",
       " 'souvent': 1,\n",
       " 'réduit': 1,\n",
       " 'vaut': 3,\n",
       " 'mieux': 5,\n",
       " 'observer': 1,\n",
       " 'milieu': 1,\n",
       " 'VI': 1,\n",
       " 'esprit': 3,\n",
       " 'vallée': 7,\n",
       " 'meurt': 3,\n",
       " 'femelle': 4,\n",
       " 'mystérieuse': 2,\n",
       " 'racine': 3,\n",
       " 'exister': 1,\n",
       " 'matériellement': 1,\n",
       " 'Si': 39,\n",
       " 'éprouve': 6,\n",
       " 'aucune': 4,\n",
       " 'fatigue': 2,\n",
       " 'VII': 1,\n",
       " 'durée': 3,\n",
       " 'S’': 24,\n",
       " 'peuvent': 10,\n",
       " 'parce': 17,\n",
       " 'vivent': 1,\n",
       " 'pour': 26,\n",
       " 'seuls': 1,\n",
       " 'après': 11,\n",
       " 'autres': 19,\n",
       " 'devient': 14,\n",
       " 'premier': 9,\n",
       " 'corps': 10,\n",
       " 'conserve': 8,\n",
       " 'N’': 2,\n",
       " '-ce': 10,\n",
       " 'intérêts': 3,\n",
       " 'privés': 3,\n",
       " '?': 28,\n",
       " 'réussir': 3,\n",
       " 'VIII': 1,\n",
       " 'vertu': 38,\n",
       " 'supérieure': 8,\n",
       " 'eau': 5,\n",
       " 'excelle': 12,\n",
       " 'faire': 8,\n",
       " 'aux': 16,\n",
       " 'lutte': 5,\n",
       " 'Elle': 1,\n",
       " 'habite': 1,\n",
       " 'lieux': 2,\n",
       " 'déteste': 2,\n",
       " 'foule': 1,\n",
       " 'sage': 8,\n",
       " 'approche': 1,\n",
       " 'plaît': 1,\n",
       " 'situation': 1,\n",
       " 'humble': 1,\n",
       " 'Son': 1,\n",
       " 'aime': 10,\n",
       " 'abîme': 1,\n",
       " 'largesses': 1,\n",
       " 'montrer': 2,\n",
       " 'humanité': 6,\n",
       " 'pratiquer': 7,\n",
       " 'vérité': 2,\n",
       " 'procurer': 2,\n",
       " 'paix': 5,\n",
       " 'agit': 6,\n",
       " 'capacité': 2,\n",
       " 'meut': 1,\n",
       " 'conformer': 1,\n",
       " 'temps': 4,\n",
       " 'contre': 2,\n",
       " 'personne': 19,\n",
       " 'reçoit': 1,\n",
       " 'marque': 1,\n",
       " 'blâme': 1,\n",
       " 'IX': 1,\n",
       " 'remplir': 1,\n",
       " 'vase': 3,\n",
       " 'vouloir': 2,\n",
       " 'maintenir': 2,\n",
       " 'plein': 6,\n",
       " 'aiguise': 1,\n",
       " 'lame': 1,\n",
       " 'explore': 1,\n",
       " 'main': 1,\n",
       " 'pourra': 9,\n",
       " 'conserver': 5,\n",
       " 'tranchante': 1,\n",
       " 'salle': 1,\n",
       " 'remplie': 1,\n",
       " 'or': 1,\n",
       " 'pierres': 2,\n",
       " 'précieuses': 3,\n",
       " 'garder': 1,\n",
       " 'comblé': 1,\n",
       " 'honneurs': 2,\n",
       " 'enorgueillisse': 1,\n",
       " 'attirera': 1,\n",
       " 'malheurs': 2,\n",
       " 'Lorsqu’': 6,\n",
       " 'grandes': 17,\n",
       " 'obtenu': 8,\n",
       " 'réputation': 1,\n",
       " 'faut': 5,\n",
       " 'retirer': 1,\n",
       " 'écart': 1,\n",
       " 'Telle': 5,\n",
       " 'X.': 1,\n",
       " 'âme': 4,\n",
       " 'doit': 9,\n",
       " 'commander': 2,\n",
       " 'sensitive': 1,\n",
       " 'unité': 2,\n",
       " 'elles': 4,\n",
       " 'pourront': 1,\n",
       " 'rester': 3,\n",
       " 'indissolubles': 1,\n",
       " 'dompte': 3,\n",
       " 'force': 7,\n",
       " 'vitale': 3,\n",
       " 'rend': 1,\n",
       " 'extrêmement': 1,\n",
       " 'souple': 3,\n",
       " 'nouveau': 3,\n",
       " '-': 32,\n",
       " 'né': 6,\n",
       " 'délivre': 1,\n",
       " 'lumières': 5,\n",
       " 'intelligence': 4,\n",
       " 'toute': 4,\n",
       " 'infirmité': 1,\n",
       " 'chérit': 1,\n",
       " 'procure': 3,\n",
       " 'royaume': 24,\n",
       " 'laisse': 10,\n",
       " 'portes': 2,\n",
       " 'ouvrir': 2,\n",
       " 'fermer': 2,\n",
       " 'dire': 7,\n",
       " 'repos': 10,\n",
       " 'pénètrent': 1,\n",
       " 'paraître': 3,\n",
       " 'nourrit': 5,\n",
       " 'propriété': 1,\n",
       " 'règne': 3,\n",
       " 'traite': 3,\n",
       " 'ce': 40,\n",
       " 'posséder': 3,\n",
       " 'profonde': 3,\n",
       " 'XI': 1,\n",
       " 'Trente': 1,\n",
       " 'rais': 1,\n",
       " 'réunissent': 2,\n",
       " 'autour': 1,\n",
       " 'moyeu': 1,\n",
       " 'dépend': 3,\n",
       " 'char': 3,\n",
       " 'pétrit': 1,\n",
       " 'glaise': 1,\n",
       " 'vases': 2,\n",
       " 'perce': 1,\n",
       " 'fenêtres': 1,\n",
       " 'maison': 3,\n",
       " 'utilité': 1,\n",
       " 'naît': 2,\n",
       " 'XII': 1,\n",
       " 'cinq': 3,\n",
       " 'couleurs': 1,\n",
       " 'émoussent': 3,\n",
       " 'vue': 1,\n",
       " 'notes': 1,\n",
       " 'musique': 2,\n",
       " 'ouïe': 1,\n",
       " 'saveurs': 1,\n",
       " 'goût': 1,\n",
       " 'courses': 1,\n",
       " 'violentes': 1,\n",
       " 'exercice': 1,\n",
       " 'chasse': 1,\n",
       " 'égarent': 1,\n",
       " 'poussent': 1,\n",
       " 'actes': 2,\n",
       " 'lui': 30,\n",
       " 'nuisent': 1,\n",
       " 'occupe': 8,\n",
       " 'yeux': 5,\n",
       " 'renonce': 1,\n",
       " 'ceci': 3,\n",
       " 'adopte': 4,\n",
       " 'cela': 10,\n",
       " 'XIII': 1,\n",
       " 'redoute': 4,\n",
       " 'gloire': 6,\n",
       " 'ignominie': 5,\n",
       " 'pèse': 2,\n",
       " 'grande': 16,\n",
       " 'calamité': 5,\n",
       " 'Qu’': 7,\n",
       " 'entend': 2,\n",
       " '-on': 3,\n",
       " 'ces': 7,\n",
       " 'mots': 2,\n",
       " ':': 19,\n",
       " 'quelque': 4,\n",
       " 'chose': 6,\n",
       " 'obtenue': 1,\n",
       " 'rempli': 3,\n",
       " 'crainte': 2,\n",
       " 'perdue': 1,\n",
       " 'dit': 7,\n",
       " 'nous': 8,\n",
       " 'éprouvons': 1,\n",
       " 'calamités': 3,\n",
       " 'avons': 2,\n",
       " 'Quand': 22,\n",
       " 'quand': 4,\n",
       " 'sommes': 1,\n",
       " 'dégagés': 1,\n",
       " 'notre': 8,\n",
       " 'quelles': 1,\n",
       " 'pourrions': 1,\n",
       " '-nous': 1,\n",
       " 'éprouver': 1,\n",
       " 'gouverner': 13,\n",
       " 'lui-même': 13,\n",
       " 'empire': 38,\n",
       " 'confier': 1,\n",
       " 'regret': 1,\n",
       " 'remettre': 1,\n",
       " 'soin': 3,\n",
       " 'XIV': 1,\n",
       " 'Vous': 3,\n",
       " 'regardez': 1,\n",
       " 'vous': 20,\n",
       " 'voyez': 3,\n",
       " 'incolore': 1,\n",
       " 'écoutez': 1,\n",
       " 'entendez': 1,\n",
       " 'aphone': 1,\n",
       " 'voulez': 2,\n",
       " 'toucher': 1,\n",
       " 'atteignez': 1,\n",
       " 'incorporel': 1,\n",
       " 'trois': 6,\n",
       " 'qualités': 1,\n",
       " 'scrutées': 1,\n",
       " 'aide': 3,\n",
       " 'confond': 1,\n",
       " 'seule': 2,\n",
       " 'Sa': 1,\n",
       " 'partie': 3,\n",
       " 'éclairée': 1,\n",
       " 'inférieure': 3,\n",
       " 'obscure': 1,\n",
       " 'rentre': 1,\n",
       " 'image': 4,\n",
       " 'vague': 5,\n",
       " 'indéterminé': 1,\n",
       " 'allez': 1,\n",
       " 'devant': 4,\n",
       " 'face': 2,\n",
       " 'suivez': 1,\n",
       " 'dos': 1,\n",
       " 'observant': 1,\n",
       " 'anciens': 6,\n",
       " 'existences': 1,\n",
       " 'aujourd’hui': 3,\n",
       " 'connaître': 3,\n",
       " 'anciennes': 1,\n",
       " 'tient': 3,\n",
       " 'fil': 1,\n",
       " 'XV': 1,\n",
       " 'Antiquité': 2,\n",
       " 'excellaient': 2,\n",
       " 'étaient': 10,\n",
       " 'déliés': 1,\n",
       " 'subtils': 1,\n",
       " 'abstraits': 1,\n",
       " 'pénétrants': 1,\n",
       " 'tellement': 1,\n",
       " 'profonds': 1,\n",
       " 'pouvait': 2,\n",
       " 'Comme': 3,\n",
       " 'je': 42,\n",
       " 'm’': 7,\n",
       " 'efforcerai': 1,\n",
       " 'donner': 6,\n",
       " 'idée': 1,\n",
       " 'timides': 1,\n",
       " 'celui': 31,\n",
       " 'traverse': 2,\n",
       " 'torrent': 1,\n",
       " 'hiver': 1,\n",
       " 'irrésolus': 1,\n",
       " 'craint': 8,\n",
       " \"d'\": 2,\n",
       " 'aperçu': 1,\n",
       " 'voisins': 1,\n",
       " 'graves': 2,\n",
       " 'étranger': 2,\n",
       " 'présence': 1,\n",
       " 'hôte': 1,\n",
       " 'effaçaient': 1,\n",
       " 'glace': 1,\n",
       " 'fond': 1,\n",
       " 'rudes': 1,\n",
       " 'bois': 3,\n",
       " 'non': 1,\n",
       " 'travaillé': 1,\n",
       " 'vides': 2,\n",
       " 'troubles': 1,\n",
       " 'limoneuse': 1,\n",
       " 'Qui': 4,\n",
       " 'sait': 22,\n",
       " 'apaiser': 2,\n",
       " 'peu': 10,\n",
       " 'laissant': 1,\n",
       " 'reposer': 1,\n",
       " 'naître': 4,\n",
       " 'vie': 16,\n",
       " 'calme': 10,\n",
       " 'prolongé': 1,\n",
       " 'désire': 6,\n",
       " 'garde': 7,\n",
       " 'défauts': 1,\n",
       " 'apparents': 1,\n",
       " 'jugé': 1,\n",
       " 'parfait': 3,\n",
       " 'XVI': 1,\n",
       " 'parvenu': 1,\n",
       " 'comble': 5,\n",
       " 'fermement': 1,\n",
       " 'dix': 5,\n",
       " 'mille': 5,\n",
       " 'ensemble': 3,\n",
       " 'ensuite': 1,\n",
       " 'vois': 2,\n",
       " 'retourner': 1,\n",
       " 'Après': 2,\n",
       " 'été': 2,\n",
       " 'état': 2,\n",
       " 'florissant': 1,\n",
       " 'chacun': 1,\n",
       " 'revient': 4,\n",
       " 'Revenir': 2,\n",
       " 'Être': 1,\n",
       " 'revenir': 2,\n",
       " 'constant': 6,\n",
       " 'Savoir': 3,\n",
       " 'éclairé': 8,\n",
       " 'abandonne': 3,\n",
       " 'désordre': 5,\n",
       " 'attire': 1,\n",
       " 'large': 2,\n",
       " 'juste': 3,\n",
       " 'roi': 6,\n",
       " 'associe': 2,\n",
       " 'imite': 8,\n",
       " 'subsiste': 4,\n",
       " 'longtemps': 8,\n",
       " 'jusqu’': 9,\n",
       " 'fin': 7,\n",
       " 'exposé': 3,\n",
       " 'aucun': 2,\n",
       " 'danger': 2,\n",
       " 'XVII': 1,\n",
       " 'Haute': 1,\n",
       " 'savait': 1,\n",
       " 'seulement': 1,\n",
       " 'avait': 2,\n",
       " 'rois': 9,\n",
       " 'suivants': 3,\n",
       " 'aima': 1,\n",
       " 'donna': 1,\n",
       " 'louanges': 1,\n",
       " 'craignit': 1,\n",
       " 'méprisa': 1,\n",
       " 'confiance': 2,\n",
       " 'obtient': 1,\n",
       " 'premiers': 1,\n",
       " 'réservés': 1,\n",
       " 'leurs': 4,\n",
       " 'paroles': 8,\n",
       " 'avaient': 1,\n",
       " 'acquis': 1,\n",
       " 'réussi': 1,\n",
       " 'desseins': 1,\n",
       " 'cent': 4,\n",
       " 'familles': 3,\n",
       " 'disaient': 2,\n",
       " 'Nous': 1,\n",
       " 'suivons': 1,\n",
       " 'nature': 6,\n",
       " 'XVIII': 1,\n",
       " 'eut': 2,\n",
       " 'dépéri': 1,\n",
       " 'vit': 4,\n",
       " 'justice': 2,\n",
       " 'prudence': 6,\n",
       " 'perspicacité': 1,\n",
       " 'furent': 2,\n",
       " 'montrées': 1,\n",
       " 'hypocrisie': 1,\n",
       " 'six': 1,\n",
       " 'parents': 1,\n",
       " 'eurent': 1,\n",
       " 'cessé': 1,\n",
       " 'vivre': 5,\n",
       " 'bonne': 2,\n",
       " 'harmonie': 4,\n",
       " 'piété': 2,\n",
       " 'filiale': 2,\n",
       " 'paternelle': 2,\n",
       " 'États': 1,\n",
       " 'tombés': 1,\n",
       " 'sujets': 1,\n",
       " 'fidèles': 1,\n",
       " 'dévoués': 1,\n",
       " 'XIX': 1,\n",
       " 'renoncez': 3,\n",
       " 'sagesse': 2,\n",
       " 'quittez': 3,\n",
       " 'sera': 1,\n",
       " 'fois': 4,\n",
       " 'heureux': 2,\n",
       " 'reviendra': 4,\n",
       " 'habileté': 2,\n",
       " 'lucre': 2,\n",
       " 'voleurs': 2,\n",
       " 'brigands': 1,\n",
       " 'disparaîtront': 1,\n",
       " 'Renoncez': 2,\n",
       " 'persuadez': 1,\n",
       " '-vous': 3,\n",
       " 'apparence': 1,\n",
       " 'suffit': 1,\n",
       " 'montre': 1,\n",
       " 'quoi': 1,\n",
       " 'doivent': 2,\n",
       " 'attacher': 1,\n",
       " 'tâchent': 1,\n",
       " 'laisser': 2,\n",
       " 'voir': 4,\n",
       " 'simplicité': 4,\n",
       " 'pureté': 4,\n",
       " 'XX': 1,\n",
       " 'étude': 4,\n",
       " 'serez': 1,\n",
       " 'chagrins': 1,\n",
       " 'Combien': 2,\n",
       " 'petite': 1,\n",
       " 'différence': 2,\n",
       " 'weï': 1,\n",
       " 'oui': 2,\n",
       " 'bref': 1,\n",
       " 'o': 1,\n",
       " 'lent': 2,\n",
       " 'Ce': 18,\n",
       " 'craignent': 1,\n",
       " 'empêcher': 1,\n",
       " 'craindre': 3,\n",
       " 'abandonnent': 1,\n",
       " 'arrêtent': 2,\n",
       " 'jamais': 4,\n",
       " 'multitude': 5,\n",
       " 'exaltés': 1,\n",
       " 'joie': 1,\n",
       " 'repaît': 1,\n",
       " 'mets': 3,\n",
       " 'succulents': 1,\n",
       " 'monté': 2,\n",
       " 'printemps': 1,\n",
       " 'tour': 2,\n",
       " 'élevée': 1,\n",
       " 'Moi': 3,\n",
       " 'seul': 8,\n",
       " 'suis': 10,\n",
       " 'mes': 3,\n",
       " 'affections': 1,\n",
       " 'encore': 5,\n",
       " 'germé': 1,\n",
       " 'Je': 18,\n",
       " 'souri': 1,\n",
       " 'détaché': 1,\n",
       " 'dirait': 1,\n",
       " 'sais': 7,\n",
       " 'où': 9,\n",
       " 'aller': 3,\n",
       " 'superflu': 5,\n",
       " 'moi': 5,\n",
       " 'perdu': 5,\n",
       " 'borné': 3,\n",
       " 'dépourvu': 1,\n",
       " 'connaissances': 2,\n",
       " 'remplis': 1,\n",
       " 'plongé': 1,\n",
       " 'ténèbres': 3,\n",
       " 'doués': 2,\n",
       " 'pénétration': 1,\n",
       " 'j’': 5,\n",
       " 'ai': 4,\n",
       " 'confus': 5,\n",
       " 'mer': 1,\n",
       " 'flotte': 1,\n",
       " 'savais': 1,\n",
       " 'arrêter': 2,\n",
       " 'stupide': 2,\n",
       " 'rustique': 1,\n",
       " 'diffère': 1,\n",
       " 'révère': 1,\n",
       " 'XXI': 1,\n",
       " 'formes': 1,\n",
       " 'visibles': 1,\n",
       " 'Vertu': 4,\n",
       " 'émanent': 1,\n",
       " 'uniquement': 5,\n",
       " 'Voici': 3,\n",
       " 'quelle': 1,\n",
       " 'Au': 4,\n",
       " 'dedans': 5,\n",
       " 'images': 1,\n",
       " \"Qu'\": 1,\n",
       " \"qu'\": 2,\n",
       " 'obscur': 1,\n",
       " 'Cette': 2,\n",
       " 'profondément': 1,\n",
       " 'vraie': 1,\n",
       " 'réside': 1,\n",
       " 'témoignage': 1,\n",
       " 'infaillible': 1,\n",
       " 'depuis': 2,\n",
       " 'passé': 1,\n",
       " 'donne': 5,\n",
       " 'issue': 1,\n",
       " 'naissance': 1,\n",
       " '-je': 3,\n",
       " 'ainsi': 5,\n",
       " 'XXII': 1,\n",
       " 'incomplet': 2,\n",
       " 'entier': 3,\n",
       " 'courbé': 1,\n",
       " 'droit': 5,\n",
       " 'creux': 1,\n",
       " 'usé': 1,\n",
       " 'neuf': 2,\n",
       " 'Avec': 2,\n",
       " 'acquiert': 1,\n",
       " 'égare': 1,\n",
       " 'Unité': 8,\n",
       " 'modèle': 6,\n",
       " 'lumière': 4,\n",
       " 'brille': 2,\n",
       " 'approuve': 2,\n",
       " 'jette': 1,\n",
       " 'éclat': 2,\n",
       " 'vante': 3,\n",
       " 'mérite': 5,\n",
       " 'glorifie': 4,\n",
       " 'supérieur': 2,\n",
       " 'puisse': 2,\n",
       " 'lutter': 2,\n",
       " 'axiome': 1,\n",
       " 'était': 2,\n",
       " 'expression': 1,\n",
       " 'sens': 1,\n",
       " 'devenu': 3,\n",
       " 'véritablement': 1,\n",
       " 'soumettre': 2,\n",
       " 'XXIII': 1,\n",
       " 'arrive': 2,\n",
       " 'Un': 4,\n",
       " 'rapide': 1,\n",
       " 'dure': 3,\n",
       " 'matinée': 1,\n",
       " 'pluie': 1,\n",
       " 'violente': 1,\n",
       " 'jour': 6,\n",
       " 'forte': 2,\n",
       " 'raison': 4,\n",
       " 'livre': 5,\n",
       " 'identifie': 5,\n",
       " 'crime': 5,\n",
       " 'gagne': 2,\n",
       " 'honte': 1,\n",
       " 'croit': 1,\n",
       " 'fortement': 2,\n",
       " 'finit': 1,\n",
       " 'croire': 3,\n",
       " 'XXIV': 1,\n",
       " 'dresse': 1,\n",
       " 'pieds': 1,\n",
       " 'tenir': 3,\n",
       " 'étend': 2,\n",
       " 'jambes': 1,\n",
       " 'marcher': 3,\n",
       " 'vues': 1,\n",
       " 'juge': 6,\n",
       " 'cette': 4,\n",
       " 'conduite': 3,\n",
       " 'selon': 1,\n",
       " 'compare': 1,\n",
       " 'reste': 4,\n",
       " 'aliments': 1,\n",
       " 'ou': 8,\n",
       " 'goitre': 1,\n",
       " 'hideux': 1,\n",
       " 'inspirent': 1,\n",
       " 'dégoût': 2,\n",
       " 'possède': 8,\n",
       " 'XXV': 1,\n",
       " 'existait': 1,\n",
       " 'avant': 6,\n",
       " 'immatériel': 2,\n",
       " 'change': 1,\n",
       " 'circule': 1,\n",
       " 'partout': 2,\n",
       " 'périclite': 3,\n",
       " 'regardé': 1,\n",
       " 'univers': 6,\n",
       " 'Pour': 4,\n",
       " 'titre': 1,\n",
       " 'efforçant': 1,\n",
       " 'grand': 21,\n",
       " 'fugace': 2,\n",
       " 'éloigné': 2,\n",
       " 'D’': 1,\n",
       " 'aussi': 6,\n",
       " 'quatre': 1,\n",
       " 'XXVI': 1,\n",
       " 'grave': 1,\n",
       " 'léger': 1,\n",
       " 'marche': 1,\n",
       " 'écarte': 2,\n",
       " 'quiétude': 4,\n",
       " 'gravité': 1,\n",
       " 'Quoiqu’': 2,\n",
       " 'palais': 2,\n",
       " 'magnifiques': 1,\n",
       " 'fuit': 1,\n",
       " 'Mais': 6,\n",
       " 'hélas': 1,\n",
       " 'maîtres': 1,\n",
       " 'chars': 2,\n",
       " 'conduisent': 1,\n",
       " 'légèrement': 1,\n",
       " 'Par': 3,\n",
       " 'légère': 4,\n",
       " 'perd': 5,\n",
       " 'ministres': 2,\n",
       " 'emportement': 1,\n",
       " 'trône': 1,\n",
       " 'XXVII': 1,\n",
       " 'traces': 1,\n",
       " 'parler': 5,\n",
       " 'commet': 1,\n",
       " 'fautes': 2,\n",
       " 'compter': 1,\n",
       " 'sert': 6,\n",
       " 'instruments': 5,\n",
       " 'calcul': 1,\n",
       " 'verrou': 1,\n",
       " 'impossible': 3,\n",
       " 'lier': 1,\n",
       " 'cordes': 1,\n",
       " 'délier': 1,\n",
       " 'Saint': 23,\n",
       " 'sauver': 3,\n",
       " 'Cela': 4,\n",
       " 'vertueux': 16,\n",
       " 'secours': 3,\n",
       " 'estime': 7,\n",
       " 'affectionne': 2,\n",
       " 'accorderait': 1,\n",
       " 'plongés': 2,\n",
       " 'aveuglement': 1,\n",
       " 'Voilà': 7,\n",
       " 'important': 1,\n",
       " 'subtil': 1,\n",
       " 'XXVIII': 1,\n",
       " 'connaît': 16,\n",
       " 'faiblesse': 4,\n",
       " 'centre': 1,\n",
       " 'accourt': 1,\n",
       " 'constante': 3,\n",
       " 'abandonnera': 1,\n",
       " 'enfant': 2,\n",
       " 'faillira': 1,\n",
       " 'atteindra': 1,\n",
       " 'perfection': 4,\n",
       " 'parfaite': 2,\n",
       " 'répandue': 1,\n",
       " 'elle': 14,\n",
       " 'formé': 1,\n",
       " 'élevé': 2,\n",
       " 'emplois': 1,\n",
       " 'chef': 4,\n",
       " 'magistrats': 1,\n",
       " 'grandement': 6,\n",
       " 'blesse': 4,\n",
       " 'XXIX': 1,\n",
       " 'parfaitement': 1,\n",
       " 'réussira': 1,\n",
       " 'divin': 1,\n",
       " 'auquel': 1,\n",
       " 'travailler': 1,\n",
       " 'travaille': 1,\n",
       " 'détruit': 1,\n",
       " 'veut': 9,\n",
       " 'saisir': 3,\n",
       " 'parmi': 2,\n",
       " 'uns': 6,\n",
       " 'marchent': 1,\n",
       " 'suivent': 1,\n",
       " 'réchauffent': 1,\n",
       " 'refroidissent': 1,\n",
       " 'forts': 1,\n",
       " 'faibles': 2,\n",
       " 'meuvent': 1,\n",
       " 'supprime': 1,\n",
       " 'excès': 1,\n",
       " 'luxe': 1,\n",
       " 'magnificence': 1,\n",
       " 'XXX': 1,\n",
       " 'subjuguer': 3,\n",
       " 'armes': 7,\n",
       " 'Quoi': 1,\n",
       " 'fasse': 3,\n",
       " 'rendent': 1,\n",
       " 'pareille': 1,\n",
       " 'Partout': 1,\n",
       " 'séjournent': 1,\n",
       " 'troupes': 1,\n",
       " 'épines': 1,\n",
       " 'ronces': 1,\n",
       " 'À': 2,\n",
       " 'suite': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "0300457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 1886\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille du vocabulaire :\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "11df4f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre des mots ayant des occurrences > 5 : 246\n"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for elem in vocab.keys() : \n",
    "    if vocab[elem] > 5 :\n",
    "        cpt += 1 \n",
    "print(\"Nombre des mots ayant des occurrences > 5 :\",cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946620d9",
   "metadata": {},
   "source": [
    "Mots les plus fréquents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "96bbdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(vocab.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7caf4c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 717),\n",
       " (',', 411),\n",
       " ('est', 325),\n",
       " ('de', 309),\n",
       " ('le', 307),\n",
       " ('et', 242),\n",
       " ('les', 233),\n",
       " ('l’', 228),\n",
       " ('il', 226),\n",
       " ('la', 224)]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12718e89",
   "metadata": {},
   "source": [
    "Mots les moins fréquents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0a95671c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chiens', 1),\n",
       " ('entendissent', 1),\n",
       " ('mon', 1),\n",
       " ('arriverait', 1),\n",
       " ('vieillesse', 1),\n",
       " ('visité', 1),\n",
       " ('voisin', 1),\n",
       " ('LXXXI', 1),\n",
       " ('intérêt', 1),\n",
       " ('nuit', 1)]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985f0c3",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "2. Extrayez le dictionnaire de bigrammes (Pensez à ajouter des tokens `<s>` et `</s>` en début et en fin de phrase/séquence). Combien de bigrammes ? Les + fréquents ? Les - fréquents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "006fb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bigram= dict()\n",
    "for phrase in sphrases : \n",
    "    for i in range(len(phrase)) :\n",
    "        if i == 0 : \n",
    "            bigram = \"<s> \" + phrase[i].text\n",
    "            \n",
    "        elif i == len(phrase) -1 : \n",
    "            bigram = phrase[i].text + \" </s>\"\n",
    "        else : \n",
    "            bigram = phrase[i].text + \" \" + phrase[i+1].text\n",
    "        if bigram in vocab_bigram : \n",
    "            vocab_bigram[bigram] += 1\n",
    "        else :\n",
    "            vocab_bigram[bigram] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d0c43fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de bigrammes : 5812\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de bigrammes :\", len(vocab_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "6d533c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(vocab_bigram.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da07f05",
   "metadata": {},
   "source": [
    "Bigrammes les + fréquents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7a9dca6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('. </s>', 685),\n",
       " ('<s> CHAPITRE', 81),\n",
       " (', il', 79),\n",
       " ('<s> Il', 77),\n",
       " ('<s> Celui', 65),\n",
       " ('est pourquoi', 64),\n",
       " ('<s> C’', 55),\n",
       " (', et', 54),\n",
       " ('de l’', 52),\n",
       " ('le Tao', 43)]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edeaeb",
   "metadata": {},
   "source": [
    "Bigrammes les - fréquents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "512a0595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donne aux', 1),\n",
       " ('plus il', 1),\n",
       " ('enrichit .', 1),\n",
       " ('utile aux', 1),\n",
       " ('leur nuit', 1),\n",
       " ('nuit point', 1),\n",
       " ('du Saint', 1),\n",
       " ('Saint ,', 1),\n",
       " ('agit et', 1),\n",
       " ('dispute point', 1)]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abd9e2",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "3. Découper le corpus en train/test (90%/10%). Estimer les proba bi-gram sur train.\n",
    "Calculer les log-proba des phrases de test. Calculer la perplexité. Comparer à la perplexité du modèle unigramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "a9cb9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "test = random.sample(sphrases, int(0.1*len(sphrases))) \n",
    "train = [x for x in sphrases if x not in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "77169dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 74\n"
     ]
    }
   ],
   "source": [
    "print(len(train) , len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b06480ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_train = dict()\n",
    "voc_train['<s>'] = len(train)\n",
    "voc_train['</s>'] = len(train)\n",
    "for phrase in train : \n",
    "    for token in phrase : \n",
    "        if token.text in voc_train : \n",
    "            voc_train[token.text] += 1\n",
    "        else :\n",
    "            voc_train[token.text] = 1 \n",
    "len(voc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "270ecf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bigram_train = dict()\n",
    "\n",
    "for phrase in train : \n",
    "    for i in range(len(phrase)) :\n",
    "        if i == 0 : \n",
    "            bigram = \"<s> \" + phrase[i].text\n",
    "            \n",
    "        elif i == len(phrase) -1 : \n",
    "            bigram = phrase[i].text + \" </s>\"\n",
    "        else : \n",
    "            bigram = phrase[i].text + \" \" + phrase[i+1].text\n",
    "        if bigram in vocab_bigram_train : \n",
    "            vocab_bigram_train[bigram] += 1\n",
    "        else :\n",
    "            vocab_bigram_train[bigram] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "0fc89563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10538\n"
     ]
    }
   ],
   "source": [
    "print(sum(vocab_bigram_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5c7b2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11876\n"
     ]
    }
   ],
   "source": [
    "print(sum(voc_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "15ec2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "f58800d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_bi = dict()\n",
    "for elem in vocab_bigram_train.keys() : \n",
    "    proba = vocab_bigram_train[elem]/voc_train[elem.split(' ')[0]] \n",
    "    probas_bi[elem] = np.log(proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "1a20c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "total_words = 0\n",
    "total_log_prob = 0 \n",
    "for phrase in test:\n",
    "    for i  in range(len(phrase)) :\n",
    "        if i == 0 : \n",
    "            bigram = \"<s> \" + phrase[i].text\n",
    "            \n",
    "        elif i == len(phrase) -1 : \n",
    "            bigram = phrase[i].text + \" </s>\"\n",
    "        else : \n",
    "            bigram = phrase[i].text + \" \" + phrase[i+1].text\n",
    "            if bigram in vocab_bigram_train.keys() : \n",
    "                total_log_prob += probas_bi[bigram]\n",
    "            \n",
    "        total_words += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "91df972d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2678574898307624"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = np.exp(-total_log_prob / total_words)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23598a8f",
   "metadata": {},
   "source": [
    "### Perplexité unigramme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "fb3bcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_uni = dict()\n",
    "total_word_count = sum(voc_train.values())  # Total count of words in the training data\n",
    "\n",
    "for word in voc_train.keys():\n",
    "    proba = np.log((voc_train[word] ) / (total_word_count ))\n",
    "    probas_uni[word] = proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "f306c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "total_log_prob = 0 \n",
    "for phrase in test:\n",
    "    for word in phrase :\n",
    "        if word.text in probas_uni.keys():\n",
    "            total_log_prob += probas_uni[word.text]\n",
    "        else:\n",
    "            # Handle unseen words with smoothing or other methods\n",
    "            total_log_prob += np.log(1 / (total_word_count + len(voc_train)))\n",
    "\n",
    "        total_words += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "79aaf070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389.87893264337885"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = np.exp(-total_log_prob / total_words)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8afad6",
   "metadata": {},
   "source": [
    "### Comparaison : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76edaf5",
   "metadata": {},
   "source": [
    "On peut voir que la perplexité d'unigramme est énormement plus grande que celle de bigramme, Un perplexité élevé peut indiquer que le modèle ne comprend pas bien les relations entre les mots ou la structure de la langue. cela parceque le modèle n'arrive pas a voir les suites des mots donc il peut pas voir la probabilté des suites des mots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65f95",
   "metadata": {},
   "source": [
    "## Question 4 : \n",
    "\n",
    "Génerer du text en unigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f1576909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial word\n",
    "generated_text = [\"<s>\"]\n",
    "\n",
    "while generated_text[-1] != \"</s>\":\n",
    "    next_word = np.random.choice(list(probas_uni.keys()), p=[np.exp(probas_uni[word]) for word in probas_uni])\n",
    "    generated_text.append(next_word)\n",
    "\n",
    "generated_text = \" \".join(generated_text[1:-1])  # Remove <s> and </s> for final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "84f78c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conserver ; . on celui sort sur devient . les a dignité Vous sur ne Celui plénitude l’ chacun le'"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ad4c4",
   "metadata": {},
   "source": [
    "## Question 5 :\n",
    "Générer du text en bigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "563c6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’ être éclairé . Il n’ est point .\n"
     ]
    }
   ],
   "source": [
    "generated_text = [\"<s>\"]\n",
    "current_word = \"<s>\"\n",
    "\n",
    "# Generate text\n",
    "while current_word != \"</s>\":\n",
    "    \n",
    "    if current_word == \"<s>\":\n",
    "        # If the current word is the starting symbol, choose the next word without considering it\n",
    "        possible_next_words = [word for word in probas_bi.keys() if word.startswith(\"<s>\")]\n",
    "    else:\n",
    "        # For other words, create a list of possible next words based on the bigram model\n",
    "        possible_next_words = [word for word in probas_bi.keys() if word.startswith(current_word + \" \")]\n",
    "\n",
    "    \n",
    "    # Calculate the probabilities for the possible next words\n",
    "    next_word_probs = [np.exp(probas_bi[word]) for word in possible_next_words]\n",
    "    next_word_probs_sum = sum(next_word_probs)\n",
    "    \n",
    "    normalized_probs = [prob / next_word_probs_sum for prob in next_word_probs]\n",
    "    # Choose the next word randomly based on probabilities\n",
    "    next_word = np.random.choice(possible_next_words, p=normalized_probs)\n",
    "    \n",
    "    # Extract the last word from the bigram to add to the generated text\n",
    "    generated_text.append(next_word.split(\" \")[-1])\n",
    "    \n",
    "    # Update the current word for the next iteration\n",
    "    current_word = next_word.split()[-1]\n",
    "\n",
    "# Convert the generated text to a string (excluding \"<s>\" and \"</s>\")\n",
    "generated_text = \" \".join(generated_text[1:-1])\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b3742",
   "metadata": {},
   "source": [
    "### Comparaison des résultats de text : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bfaa24",
   "metadata": {},
   "source": [
    "on peut voir clairement que le bigramme donne un texte plus ou moins logique malgrè qu'il a pas de vrai sense mais au moins il respectent les règles de la langue comme par example le l' et et n' on trouve des voyelle, au contraire de unigramme on trouve que y'a un C' avec un les après ce qu'est tellement pas logique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
