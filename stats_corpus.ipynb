{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de textes\n",
    "\n",
    "## Questions\n",
    "> ### Identification du thème du document\n",
    "> 1. Télécharger les données [Reuters-21578](https://huggingface.co/datasets/reuters21578)\n",
    "> 1. Extraire les textes (body) ainsi que les catégories (topics) qui leur sont associées. Garder les textes étiquetés avec les 4 catégories les plus fréquentes. \n",
    "> 1. Les tokeniser en utilisant [`spacy`](https://spacy.io/usage/spacy-101#annotations-token)\n",
    "> 1. (\\*) Représenter chaque texte par un vecteur *sac-de-mots* de comptes. (SANS utiliser CountVectorizer de sklearn)\n",
    "> 1. (\\*) En utilisant la représentation précédente entraîner un [classifieur bayésien naïf](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes). Observer les paramétres du modèle. Rapporter les performance du modèle en termes de Précision/Rappel/Score_F1. Commentez.\n",
    "\n",
    "> ### Classification de sentiments\n",
    "> 1. (\\*) Télécharger les données *sacs-de-mots* (version ACL) d'[avis](https://www.cs.jhu.edu/~mdredze/datasets/sentiment/) sur des produits d'amazon. Observer les tokens choisis. Que constatez vous?\n",
    "> 1. Entraîner un classifieur de sentiments pour ce jeu de données d'avis. Rapporter les performance du modèle en termes de Précision/Rappel/Score_F1.\n",
    "\n",
    "> ### (\\*) Similarités entre mots\n",
    "> Hypothèse à tester: La fréquence de co-occurrence des mots dans des documents est un bon indicateur de leur \"distance sémantique\".\n",
    "> 1. Soit $D$ la matrice binaire documents x mots. Soit $W = D^T D$. Quelles sont les dimensions de la matrice $W$? Comment interpréter la valeur de $W_{ij}$ (l'élément à la ième ligne et jème colonne)?\n",
    "> 1. Comment pourriez vous utilise cette matrice pour tester l'hypothèse?\n",
    "> 1. Tester sur les données reuters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install datasets # Les datasets réunis par Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"reuters21578\", 'ModLewis', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'text_type', 'topics', 'lewis_split', 'cgis_split', 'old_id', 'new_id', 'places', 'people', 'orgs', 'exchanges', 'date', 'title'],\n",
       "    num_rows: 13625\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Showers continued throughout the week in\\nthe Bahia cocoa zone, alleviating the drought since early\\nJanuary and improving prospects for the coming temporao,\\nalthough normal humidity levels have not been restored,\\nComissaria Smith said in its weekly review.\\n    The dry period means the temporao will be late this year.\\n    Arrivals for the week ended February 22 were 155,221 bags\\nof 60 kilos making a cumulative total for the season of 5.93\\nmln against 5.81 at the same stage last year. Again it seems\\nthat cocoa delivered earlier on consignment was included in the\\narrivals figures.\\n    Comissaria Smith said there is still some doubt as to how\\nmuch old crop cocoa is still available as harvesting has\\npractically come to an end. With total Bahia crop estimates\\naround 6.4 mln bags and sales standing at almost 6.2 mln there\\nare a few hundred thousand bags still in the hands of farmers,\\nmiddlemen, exporters and processors.\\n    There are doubts as to how much of this cocoa would be fit\\nfor export as shippers are now experiencing dificulties in\\nobtaining +Bahia superior+ certificates.\\n    In view of the lower quality over recent weeks farmers have\\nsold a good part of their cocoa held on consignment.\\n    Comissaria Smith said spot bean prices rose to 340 to 350\\ncruzados per arroba of 15 kilos.\\n    Bean shippers were reluctant to offer nearby shipment and\\nonly limited sales were booked for March shipment at 1,750 to\\n1,780 dlrs per tonne to ports to be named.\\n    New crop sales were also light and all to open ports with\\nJune/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\\nunder New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\\nper tonne FOB.\\n    Routine sales of butter were made. March/April sold at\\n4,340, 4,345 and 4,350 dlrs.\\n    April/May butter went at 2.27 times New York May, June/July\\nat 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\\n2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\\n2.27 times New York Dec, Comissaria Smith said.\\n    Destinations were the U.S., Covertible currency areas,\\nUruguay and open ports.\\n    Cake sales were registered at 785 to 995 dlrs for\\nMarch/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\\nNew York Dec for Oct/Dec.\\n    Buyers were the U.S., Argentina, Uruguay and convertible\\ncurrency areas.\\n    Liquor sales were limited with March/April selling at 2,325\\nand 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\\nYork July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\\nSept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\\nsaid.\\n    Total Bahia sales are currently estimated at 6.13 mln bags\\nagainst the 1986/87 crop and 1.06 mln bags against the 1987/88\\ncrop.\\n    Final figures for the period to February 28 are expected to\\nbe published by the Brazilian Cocoa Trade Commission after\\ncarnival which ends midday on February 27.\\n Reuter\\n',\n",
       " 'text_type': '\"NORM\"',\n",
       " 'topics': ['cocoa'],\n",
       " 'lewis_split': '\"TRAIN\"',\n",
       " 'cgis_split': '\"TRAINING-SET\"',\n",
       " 'old_id': '\"5544\"',\n",
       " 'new_id': '\"1\"',\n",
       " 'places': ['el-salvador', 'usa', 'uruguay'],\n",
       " 'people': [],\n",
       " 'orgs': [],\n",
       " 'exchanges': [],\n",
       " 'date': '26-FEB-1987 15:01:01.79',\n",
       " 'title': 'BAHIA COCOA REVIEW'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['title' , 'cgis_split','text_type','lewis_split','old_id','new_id','places' , 'people' , 'orgs' , 'exchanges', 'date'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['topics'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>cocoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>barley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13615</th>\n",
       "      <td>The Bank of Japan bought a small amount of\\ndo...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13616</th>\n",
       "      <td>Japan's rubber stocks fell to 44,980\\ntonnes i...</td>\n",
       "      <td>rubber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13617</th>\n",
       "      <td>THE BANK OF KOREA SAID IT FIXED THE\\nMIDRATE O...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13618</th>\n",
       "      <td>Nippon Mining Co Ltd said it lowered its\\nsell...</td>\n",
       "      <td>copper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13620</th>\n",
       "      <td>Australian trade unions said they have\\nlaunch...</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9656 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    topics\n",
       "0      Showers continued throughout the week in\\nthe ...     cocoa\n",
       "4      The U.S. Agriculture Department\\nreported the ...     grain\n",
       "4      The U.S. Agriculture Department\\nreported the ...     wheat\n",
       "4      The U.S. Agriculture Department\\nreported the ...      corn\n",
       "4      The U.S. Agriculture Department\\nreported the ...    barley\n",
       "...                                                  ...       ...\n",
       "13615  The Bank of Japan bought a small amount of\\ndo...  money-fx\n",
       "13616  Japan's rubber stocks fell to 44,980\\ntonnes i...    rubber\n",
       "13617  THE BANK OF KOREA SAID IT FIXED THE\\nMIDRATE O...  money-fx\n",
       "13618  Nippon Mining Co Ltd said it lowered its\\nsell...    copper\n",
       "13620  Australian trade unions said they have\\nlaunch...      ship\n",
       "\n",
       "[9656 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earn        2877\n",
       "acq         1650\n",
       "money-fx     539\n",
       "grain        434\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_present = df[\"topics\"].value_counts()[0:4]\n",
    "most_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Argentine grain board figures show\\ncrop regis...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Champion Products Inc said its\\nboard of direc...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Computer Terminal Systems Inc said\\nit has com...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shr 34 cts vs 1.19 dlrs\\n    Net 807,000 vs 2,...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>News of an agreement among G-5 and G-7\\nfinanc...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13611</th>\n",
       "      <td>Bundesbank President Karl Otto Poehl\\nsaid a w...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614</th>\n",
       "      <td></td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13615</th>\n",
       "      <td>The Bank of Japan bought a small amount of\\ndo...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13617</th>\n",
       "      <td>THE BANK OF KOREA SAID IT FIXED THE\\nMIDRATE O...</td>\n",
       "      <td>money-fx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    topics\n",
       "4      The U.S. Agriculture Department\\nreported the ...     grain\n",
       "5      Argentine grain board figures show\\ncrop regis...     grain\n",
       "8      Champion Products Inc said its\\nboard of direc...      earn\n",
       "9      Computer Terminal Systems Inc said\\nit has com...       acq\n",
       "10     Shr 34 cts vs 1.19 dlrs\\n    Net 807,000 vs 2,...      earn\n",
       "...                                                  ...       ...\n",
       "13608  News of an agreement among G-5 and G-7\\nfinanc...  money-fx\n",
       "13611  Bundesbank President Karl Otto Poehl\\nsaid a w...  money-fx\n",
       "13614                                                     money-fx\n",
       "13615  The Bank of Japan bought a small amount of\\ndo...  money-fx\n",
       "13617  THE BANK OF KOREA SAID IT FIXED THE\\nMIDRATE O...  money-fx\n",
       "\n",
       "[5500 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = df[df[\"topics\"].isin(['earn' , 'acq' , 'money-fx' , 'grain'])]\n",
    "df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3/4 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =  df_f['text'].apply(lambda x : nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        (The, U.S., Agriculture, Department, \\n, repor...\n",
       "5        (Argentine, grain, board, figures, show, \\n, c...\n",
       "8        (Champion, Products, Inc, said, its, \\n, board...\n",
       "9        (Computer, Terminal, Systems, Inc, said, \\n, i...\n",
       "10       (Shr, 34, cts, vs, 1.19, dlrs, \\n    , Net, 80...\n",
       "                               ...                        \n",
       "13608    (News, of, an, agreement, among, G-5, and, G-7...\n",
       "13611    (Bundesbank, President, Karl, Otto, Poehl, \\n,...\n",
       "13614                                                   ()\n",
       "13615    (The, Bank, of, Japan, bought, a, small, amoun...\n",
       "13617    (THE, BANK, OF, KOREA, SAID, IT, FIXED, THE, \\...\n",
       "Name: text, Length: 5500, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for elem in tokens : \n",
    "    \n",
    "    for token in elem : \n",
    "        if token.text not in words :\n",
    "            words.append(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "sparse_matrix = lil_matrix((len(df_f), len(words)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx, text in enumerate(df_f['text']):\n",
    "    ws = text.lower().split()\n",
    "    for w in ws:\n",
    "        if w in words:\n",
    "            col_idx = words.index(w)\n",
    "            sparse_matrix[row_idx, col_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 7.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 5.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]),\n",
       "       list([1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 13.0, 1.0, 1.0, 8.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0]),\n",
       "       list([3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0]),\n",
       "       ..., list([]),\n",
       "       list([7.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0]),\n",
       "       list([7.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>U.S.</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Department</th>\n",
       "      <th>\\n</th>\n",
       "      <th>reported</th>\n",
       "      <th>the</th>\n",
       "      <th>farmer</th>\n",
       "      <th>-</th>\n",
       "      <th>owned</th>\n",
       "      <th>...</th>\n",
       "      <th>843.90</th>\n",
       "      <th>SET</th>\n",
       "      <th>845.50</th>\n",
       "      <th>YESTERDAY</th>\n",
       "      <th>HAS</th>\n",
       "      <th>RISEN</th>\n",
       "      <th>SO</th>\n",
       "      <th>FAR</th>\n",
       "      <th>THIS</th>\n",
       "      <th>RISING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 31743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  U.S.  Agriculture  Department   \\n  reported   the  farmer    -  \\\n",
       "0     0.0   0.0          0.0         0.0  0.0       1.0   2.0     0.0  2.0   \n",
       "1     0.0   0.0          0.0         0.0  0.0       0.0   1.0     0.0  0.0   \n",
       "2     0.0   0.0          0.0         0.0  0.0       0.0   3.0     0.0  0.0   \n",
       "3     0.0   0.0          0.0         0.0  0.0       0.0  15.0     0.0  0.0   \n",
       "4     0.0   0.0          0.0         0.0  0.0       0.0   0.0     0.0  0.0   \n",
       "...   ...   ...          ...         ...  ...       ...   ...     ...  ...   \n",
       "5495  0.0   0.0          0.0         0.0  0.0       0.0  41.0     0.0  0.0   \n",
       "5496  0.0   0.0          0.0         0.0  0.0       1.0  28.0     0.0  0.0   \n",
       "5497  0.0   0.0          0.0         0.0  0.0       0.0   0.0     0.0  0.0   \n",
       "5498  0.0   0.0          0.0         0.0  0.0       0.0   7.0     0.0  0.0   \n",
       "5499  0.0   0.0          0.0         0.0  0.0       0.0   7.0     0.0  0.0   \n",
       "\n",
       "      owned  ...  843.90  SET  845.50  YESTERDAY  HAS  RISEN   SO  FAR  THIS  \\\n",
       "0       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "1       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "2       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "4       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "...     ...  ...     ...  ...     ...        ...  ...    ...  ...  ...   ...   \n",
       "5495    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5496    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5497    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5498    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5499    0.0  ...     0.0  0.0     1.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "      RISING  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "5495     0.0  \n",
       "5496     0.0  \n",
       "5497     0.0  \n",
       "5498     0.0  \n",
       "5499     0.0  \n",
       "\n",
       "[5500 rows x 31743 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse_matrix\n",
    "mapping = {\"grain\" : 3, 'money-fx' : 2 , 'acq' :1 , 'earn' : 0 }\n",
    "y= df_f['topics'].map(mapping).to_numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045454545454545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.91080617, 0.85549133, 0.96341463, 1.        ]),\n",
       " array([0.91237113, 0.90519878, 0.85869565, 0.8989899 ]),\n",
       " array([0.91158798, 0.87964339, 0.90804598, 0.94680851]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision  , recall , f1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the provided precision, recall, and F1-score metrics suggest that the model generally performs well across all four classes. However, it's important to consider the specific requirements and goals of your classification task to determine if these performance metrics are satisfactory for your application. Additionally, it's crucial to analyze other aspects of model performance, such as confusion matrices and ROC curves, to get a comprehensive understanding of its behavior.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[531,  48,   3,   0],\n",
       "       [ 31, 296,   0,   0],\n",
       "       [ 11,   2,  79,   0],\n",
       "       [ 10,   0,   0,  89]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, nothing to be worry about , the model is doing fairly good for the classification of all the classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrix W is a square matrix because it results from the multiplication of DT (term-document matrix) by D (document-term matrix).\n",
    "- If you have N documents and M unique words in your corpus, then the dimension of W will be M x M (because DT is M x N, and D is N x M).\n",
    "- Interpreted as the word at the i and j index , exist at least once in the same document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by actually calculating the W matrice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>U.S.</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Department</th>\n",
       "      <th>\\n</th>\n",
       "      <th>reported</th>\n",
       "      <th>the</th>\n",
       "      <th>farmer</th>\n",
       "      <th>-</th>\n",
       "      <th>owned</th>\n",
       "      <th>...</th>\n",
       "      <th>843.90</th>\n",
       "      <th>SET</th>\n",
       "      <th>845.50</th>\n",
       "      <th>YESTERDAY</th>\n",
       "      <th>HAS</th>\n",
       "      <th>RISEN</th>\n",
       "      <th>SO</th>\n",
       "      <th>FAR</th>\n",
       "      <th>THIS</th>\n",
       "      <th>RISING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 31743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The  U.S.  Agriculture  Department   \\n  reported  the  farmer    -  \\\n",
       "0     0.0   0.0          0.0         0.0  0.0       1.0  1.0     0.0  1.0   \n",
       "1     0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "2     0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "3     0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "4     0.0   0.0          0.0         0.0  0.0       0.0  0.0     0.0  0.0   \n",
       "...   ...   ...          ...         ...  ...       ...  ...     ...  ...   \n",
       "5495  0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "5496  0.0   0.0          0.0         0.0  0.0       1.0  1.0     0.0  0.0   \n",
       "5497  0.0   0.0          0.0         0.0  0.0       0.0  0.0     0.0  0.0   \n",
       "5498  0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "5499  0.0   0.0          0.0         0.0  0.0       0.0  1.0     0.0  0.0   \n",
       "\n",
       "      owned  ...  843.90  SET  845.50  YESTERDAY  HAS  RISEN   SO  FAR  THIS  \\\n",
       "0       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "1       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "2       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "4       0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "...     ...  ...     ...  ...     ...        ...  ...    ...  ...  ...   ...   \n",
       "5495    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5496    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5497    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5498    0.0  ...     0.0  0.0     0.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "5499    0.0  ...     0.0  0.0     1.0        0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "      RISING  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "5495     0.0  \n",
       "5496     0.0  \n",
       "5497     0.0  \n",
       "5498     0.0  \n",
       "5499     0.0  \n",
       "\n",
       "[5500 rows x 31743 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = lil_matrix((len(df_f), len(words)), dtype=np.float32)\n",
    "for row_idx, text in enumerate(df_f['text']):\n",
    "    ws = text.lower().split()\n",
    "    for w in ws:\n",
    "        if w in words:\n",
    "            col_idx = words.index(w)\n",
    "            sparse_matrix[row_idx, col_idx] = 1\n",
    "            \n",
    "sparse_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, columns=words)\n",
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = sparse_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = D.T@D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31743, 31743)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the shape is really of the MxM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can  we use this matrice to teste the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**co-occurrence matrices are often constructed from text data to capture the associations between words or terms. Each row and column in the matrix represents a word or term from the vocabulary, and the matrix cells contain binary values indicating whether two words co-occur in a specific context.**\n",
    "\n",
    "**We can test that by calculating the jaccard similarity between 2 random words for example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity between word 9 and word 7: 0.13778228875919818\n"
     ]
    }
   ],
   "source": [
    "word1_index = 9\n",
    "\n",
    "word2_index = 7\n",
    "\n",
    "# Get the rows corresponding to the two words\n",
    "word1_vector = W[word1_index].astype(bool)\n",
    "word2_vector = W[word2_index].astype(bool)\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "intersection = np.sum(word1_vector & word2_vector) #nb of documents they appeared in both \n",
    "union = np.sum(word1_vector | word2_vector) # sum of documents where they appeared\n",
    "jaccard_similarity = intersection / union\n",
    "print(f\"Jaccard Similarity between word {word1_index} and word {word2_index}: {jaccard_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('owned', 'farmer')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df.columns[9] , sparse_df.columns[7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
